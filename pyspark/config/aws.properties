
APPLICATION_ID = "your-emr-serverless-app-id"
JOB_ROLE_ARN = "your-emr-job-role-arn"
S3_INPUT_PATH = "C:\\Users\\399182\\MHCLG-Repo\\SourceFiles\\AWS-S3\\transform-access-node\\*.csv"
S3_OUTPUT_PATH = "C:\\Users\\399182\\MHCLG-Repo\\SourceFiles\\AWS-S3\\transform-access-node\\output"
SCRIPT_LOCATION = "s3://your-bucket/scripts/spark_job.py"
BUCKET_KEY='input/data.csv',
BUCKET_NAME='your-bucket',

JDBC_URL="jdbc:postgresql://your-aurora-endpoint:5432/yourdb",
TABLE_NAME="your_table_name",
USER_NAME="your_username",
PASSWORD="your_password"
LOGURI= "s3://your-bucket/logs/"

PG_JDBC = "dbc:postgresql:"
PG_URL = = "your-aurora-endpoint:5432/yourdb"
#TABLE_NAME = config.get('DEFAULT', 'TABLE_NAME')
#USER_NAME = config.get('DEFAULT', 'USER_NAME')
#PASSWORD = config.get('DEFAULT', 'PASSWORD')
DRIVER= config.get('DEFAULT', 'DRIVER')