import json
import os.path
import pytest
from pathlib import Path

from csv import DictReader

from digital_land.commands import (
    dataset_create,
    dataset_update,
    dataset_dump,
    dataset_dump_flattened,
)
from digital_land.specification import specification_path
from digital_land.specification import Specification
from digital_land.pipeline import Pipeline


@pytest.mark.skip("data needs updating")
@pytest.mark.parametrize(
    "dataset_name",
    [
        "listed-building-grade",
        "listed-building-outline",
        "locally-listed-building",
    ],
)
def test_package_dataset(
    # Parametrize args
    dataset_name,
    # Static runtime filesystem dependencies
    column_field_dir,
    dataset_resource_dir,
    organisation_path,
    # Runtime filesystem dependencies generated by previous steps
    transformed_dir,
    pipeline_dir,
    # Test assertion directories
    dataset_dir,
    # Pytest fixtures
    tmp_path,
):
    # Setup
    expected_csv_result = dataset_dir.joinpath(f"{dataset_name}.csv")

    input_paths = [
        str(transformed_path)
        for transformed_path in transformed_dir.joinpath(dataset_name).iterdir()
    ]

    output_dir = tmp_path.joinpath("dataset_output")
    output_dir.mkdir()
    sqlite_path = output_dir.joinpath(f"{dataset_name}.sqlite3")
    csv_path = output_dir.joinpath(f"{dataset_name}.csv")

    dataset_create(input_paths, sqlite_path, organisation_path)
    dataset_dump(sqlite_path, csv_path)

    # Assert
    with csv_path.open() as actual, expected_csv_result.open() as expected:
        actual_dict_reader = DictReader(actual)
        expected_dict_reader = DictReader(expected)
        assert actual_dict_reader.fieldnames == expected_dict_reader.fieldnames
        assert list(actual_dict_reader) == list(expected_dict_reader)


@pytest.mark.parametrize(
    "dataset_name",
    ["listed-building-grade"],
)
def test_package_flattened_dataset(
    # Parametrize args
    dataset_name,
    # Runtime filesystem dependencies generated by previous steps
    pipeline_dir,
    # Test assertion directories
    dataset_dir,
    # Pytest fixtures
    tmp_path,
):
    # Setup
    expected_flattened_csv_result = dataset_dir.joinpath(f"{dataset_name}-expected.csv")

    csv_path = dataset_dir.joinpath(f"{dataset_name}.csv")

    flattened_output_dir = tmp_path.joinpath("dataset_output")
    flattened_output_dir.mkdir()
    flattened_csv_path = flattened_output_dir.joinpath(f"{dataset_name}.csv")
    flattened_json_path = flattened_output_dir.joinpath(f"{dataset_name}.json")

    specification = Specification(specification_path)

    dataset_dump_flattened(csv_path, flattened_output_dir, specification, dataset_name)

    with flattened_csv_path.open() as actual, expected_flattened_csv_result.open() as expected:
        actual_dict_reader = DictReader(actual)
        expected_dict_reader = DictReader(expected)
        assert actual_dict_reader.fieldnames == expected_dict_reader.fieldnames
        assert list(actual_dict_reader) == list(expected_dict_reader)

    assert os.path.isfile(flattened_json_path)
    with flattened_json_path.open() as actual:
        data = json.load(actual)
        assert 3 == len(data["entities"])


@pytest.mark.parametrize(
    "dataset_name",
    ["listed-building-outline"],
)
def test_package_flattened_dataset_with_geographies(
    # Parametrize args
    dataset_name,
    # Runtime filesystem dependencies generated by previous steps
    pipeline_dir,
    # Test assertion directories
    dataset_dir,
    # Pytest fixtures
    tmp_path,
):
    # Setup
    expected_flattened_csv_result = dataset_dir.joinpath(f"{dataset_name}-expected.csv")

    csv_path = dataset_dir.joinpath(f"{dataset_name}.csv")

    flattened_output_dir = tmp_path.joinpath("dataset_output")
    flattened_output_dir.mkdir()
    flattened_csv_path = flattened_output_dir.joinpath(f"{dataset_name}.csv")
    flattened_json_path = flattened_output_dir.joinpath(f"{dataset_name}.json")

    specification = Specification(specification_path)

    dataset_dump_flattened(csv_path, flattened_output_dir, specification, dataset_name)

    with flattened_csv_path.open() as actual, expected_flattened_csv_result.open() as expected:
        actual_dict_reader = DictReader(actual)
        print(list(actual_dict_reader))
        expected_dict_reader = DictReader(expected)
        print(list(expected_dict_reader))
        assert actual_dict_reader.fieldnames == expected_dict_reader.fieldnames
        assert list(actual_dict_reader) == list(expected_dict_reader)

    assert os.path.isfile(flattened_json_path)
    with flattened_json_path.open() as actual:
        data = json.load(actual)
        assert 1 == len(data["entities"])


@pytest.mark.parametrize(
    "dataset_name",
    ["listed-building-outline"],
)
def test_package_dataset_create(
    dataset_name,
    column_field_dir,
    dataset_resource_dir,
    organisation_path,
    tmp_path,
):
    collection_name = "listed-building"

    test_data_path = Path("tests", "data", collection_name)

    transformed_dir = test_data_path / "transformed"

    pipeline = Pipeline(Path("tests", "data", "pipeline"), dataset_name)

    # Setup
    expected_csv_result = Path(
        "tests", "data", "expected_output", "dataset_create", f"{dataset_name}.csv"
    )

    input_paths = [
        str(transformed_path)
        for transformed_path in transformed_dir.joinpath(dataset_name).iterdir()
    ]

    output_dir = tmp_path.joinpath("dataset_output")
    output_dir.mkdir()
    sqlite_path = output_dir.joinpath(f"{dataset_name}.sqlite3")
    csv_path = output_dir.joinpath(f"{dataset_name}.csv")

    dataset_create(
        input_paths,
        sqlite_path,
        organisation_path,
        pipeline,
        dataset_name,
        None,
        "issue",
        column_field_dir,
        dataset_resource_dir,
    )
    dataset_dump(sqlite_path, csv_path)

    # Assert
    with csv_path.open() as actual, expected_csv_result.open() as expected:
        actual_dict_reader = DictReader(actual)
        expected_dict_reader = DictReader(expected)
        assert actual_dict_reader.fieldnames == expected_dict_reader.fieldnames
        assert list(actual_dict_reader) == list(expected_dict_reader)


@pytest.mark.parametrize(
    "dataset_name",
    ["listed-building-outline"],
)
def test_package_dataset_update(
    dataset_name,
    column_field_dir,
    dataset_resource_dir,
    organisation_path,
    tmp_path,
):
    collection_name = "listed-building"

    test_data_path = Path("tests", "data", collection_name)

    transformed_dir = test_data_path / "transformed"

    pipeline = Pipeline(Path("tests", "data", "pipeline"), dataset_name)

    # Setup
    expected_csv_result = Path(
        "tests", "data", "expected_output", "dataset_create", f"{dataset_name}.csv"
    )

    input_paths = [
        str(transformed_path)
        for transformed_path in transformed_dir.joinpath(dataset_name).iterdir()
    ]

    output_dir = tmp_path.joinpath("dataset_output")
    output_dir.mkdir()
    sqlite_path = output_dir.joinpath(f"{dataset_name}.sqlite3")
    csv_path = output_dir.joinpath(f"{dataset_name}.csv")

    dataset_create(
        [input_paths[0]],
        sqlite_path,
        organisation_path,
        pipeline,
        dataset_name,
        None,
        "issue",
        column_field_dir,
        dataset_resource_dir,
    )

    for input_path in input_paths[1:]:
        dataset_update(
            [input_path],
            sqlite_path,
            organisation_path,
            pipeline,
            dataset_name,
            None,
            "issue",
            column_field_dir,
            dataset_resource_dir,
        )

    dataset_dump(sqlite_path, csv_path)

    # Assert
    with csv_path.open() as actual, expected_csv_result.open() as expected:
        actual_dict_reader = DictReader(actual)
        expected_dict_reader = DictReader(expected)
        assert actual_dict_reader.fieldnames == expected_dict_reader.fieldnames
        assert list(actual_dict_reader) == list(expected_dict_reader)
